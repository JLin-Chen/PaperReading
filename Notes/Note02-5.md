# Cross-lingual COVID-19 Fake News Detection

> Jiangshu Du, Yingtong Dou, Congying Xia, Limeng Cui, Jing Ma, Philip S. Yu  
> arXiv  
> https://arxiv.org/pdf/2110.06495.pdf  

## Abstract  
文章提出中文新冠疫情新闻数据集(https://github.com/YingtongDou/CrossFake)，实现多语言场景下对虚假新闻进行分类。

# Overview  
利用预训练好的BERT在标注充足的英文数据集上进行微调，将中文翻译为英文后，再输入到微调后的BERT中，进行分类。  
> ## Model Name  
> CrossFake
> ## Motivation  
> 新冠疫情相关标注的中文数据集匮乏，不能很好地通过仅有的中文数据集进行训练与检测。通过迁移学习的方法利用英文标注数据集充足的特点进行训练能较好地解决该问题。
> ## Structure  
> ![Note02-5-1]/Img/Note02-5-1.bmp  
> ## Method  
> 把长文本(>512tokens)分解为短文本，经过平均池化和全连接网络FC后，得到某一新闻e对应的embedding：  
> ![Note02-5-3]/Img/Note02-5-3.bmp  
> 用于更新分类器C的损失函数：  
> ![Note02-5-4]/Img/Note02-5-4.bmp  
> 进行预测，其中临界值取0.8：  
> ![Note02-5-5]/Img/Note02-5-5.bmp  
> ## Experiment  
> ![Note02-5-2]/Img/Note02-5-2.bmp  
> 作者在实验时，因为数据集只使用了文本信息，所以对于其他模型的结构也进行了一定的调整
> （这种操作应该也会降低其他模型本身的效果，不过只对于文本信息学习这块的单独比较应该没有太大影响）。

## Brief Comment  
个人感觉整个模型的关键步骤在于中译英这一块，翻译的地道程度在很大程度上会影响模型分类的准确性。  

由于该实验建立数据集的方法是根据英文内容在中国网站上检索相似的新闻，从而构造中文数据集，因此对于国外信息在中国的再传播这一类型的检测会取得较好的效果，
而对于基于中国本土情况的疫情信息的检测能力应当会十分糟糕。而且就整个实验过程来看，与其说是迁移学习，不如说是将英文数据集中的新闻内容进行改写然后检测模型的分类效果。
另外，由于整个数据集的规模比较小，把它放到BERT中进行预训练是否能学到好的东西这一点也存在一定的不确定性。  

（乍一看这篇文章好像除了很辛苦地构造了数据集外，好像没做什么东西...）



