# A Survey on Neural Network Interpretability

> Yu Zhang, Peter Tino, Ale ˇ s Leonardis, and Ke Tang  
> IEEE 2020  
> https://arxiv.org/pdf/2012.14261v3.pdf  

## Abstract
这篇文章是一篇关于神经网络可解释性研究的综述性文章。它完善了可解释性的定义，提出可解释性研究的三个维度。  

# Overview
> ## Motivation
> 现有可解释性综述文章存在多而杂，内容不全，涵盖不全面等缺点，不能很好地展现可解释性研究的整体现状。故作者写此论文搭建可解释性研究的框架，为抛砖引玉之用。
> ## Definition
> Interpretability is the ability to provide **explanations** in **understandable** terms to a human.
> ## Structure
> ![Note01-1-1](/Img/Note01-1-1.bmp)  
> ![Note01-1-2](/Img/Note01-1-2.bmp)  
> ![Note01-1-3](/Img/Note01-1-3.bmp)  

## Brief Comment
在众多可解释性综述文章中，该文章搭建的三维的研究方向框架比较清晰易懂，适合从总体上了解可解释性的3W1H问题，对该领域研究有个初步的印象和从全局方面出发的粗略了解。以此论文作为可解释性研究的出发点，可以从文章的引用中不断深入学习了解各个分支的发展。

论文中提到的方法和所引用的文章大多是2018年以前的，论文的阐述重点也大多基于此前的研究开展.在搜索相关资料的过程中也发现，近年来有关可解释性研究的论文也杂而多，且近期不断有不同领域的可解释性文章的发表和相关会议的开展。个人主观认为未来可解释性研究有极大的发展空间，但也注定是道阻且长。

阅读过程中更发现，想要从“看”直至“懂”还需要更加漫长的学习过程，往往一篇文章的阅读会牵扯到许多的未知的知识。该论文既可作为开始进行可解释性学习的目录式文章，又可为某一领域的研究作启发、指导思考的方向，也可不断完善该文章中提到的各个细分，了解前沿的研究动向。
