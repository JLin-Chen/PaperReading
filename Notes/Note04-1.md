 # SVM：Support Vector Machine
 
> 支持向量与最大化间隔  
> 优化与求解  

## Abstract
SVM，即支持向量机，是一种有监督学习中的二分类模型，是定义在特征空间上的间隔最大化的线性分类器。它的基本思想为采用最大化间隔策略，
寻找一个最优决策超平面并将所有样本点划分到超平面两侧，实现对数据的分类。最大化间隔策略即求解凸二次规划问题。对于线性可分的数据集，分隔超平面（感知机）
有无穷多个，而几何间隔最大超平面是唯一的。事实上，在引入核技巧后，SVM成为实质上的非线性分类器。  
# Overview
> ## Model Name
> SVM：Support Vector Machine  
> ## 支持向量和最大化间隔  
> 
> 超平面：n维线性空间中维度为n-1的子空间，把线性空间分割成不相交的两部分。  
> ![Note04-1-1](/Img/Note04-1-1.bmp)  
> 
>  SVM算法目标：寻找一个超平面将数据集D划分为两个不相交的子集  
>  ![Note04-1-2](/Img/Note04-1-2.bmp)  
>  ![Note04-1-3](/Img/Note04-1-3.bmp)  
>
> 间隔最大化：选择离两边数据集都尽量远的超平面来划分数据空间  
> 支持向量：利用间隔最大化方法选取超平面后，两个数据集中离超平面最近的点  
>  ![Note04-1-4](/Img/Note04-1-4.bmp)  
>
> 问题转化为约束最优化问题：  
>  ![Note04-1-5](/Img/Note04-1-5.bmp)  
>  上式表明，求有多个超平面的多个取值，找到最优的取值，即找到几何间隔最大化的超平面。  
>  当参数w和b按照一定比例缩放时，函数距离也会跟着比例缩放，但所确定的超平面不会改变。
>  故为化简计算进行数学变化，缩放函数距离到1，最优化问题化简为：  
>   ![Note04-1-6](/Img/Note04-1-6.bmp)  
>   上述最大化问题与下述最小值优化问题等价（凸二次优化问题）（数学上的变化？）： 
>   ![Note04-1-7](/Img/Note04-1-7.bmp)   
>   
> ## 优化与求解  
> 凸二次优化问题：目标函数是二次函数且约束函数是线性的。  
> 这类问题通常采用引入拉格朗日乘子法进行转化，将有约束条件的问题转化为无约束条件的问题进行求解：  
>  ![Note04-1-8](/Img/Note04-1-8.bmp)   
>
> 此时对参数w和b已经没有约束条件。根据拉格朗日对偶性，将上式中求最大值的最小值问题转化为求最小值的最大值问题：  
>  ![Note04-1-9](/Img/Note04-1-9.bmp)   
>  ![Note04-1-10](/Img/Note04-1-10.bmp)   
>  ![Note04-1-11](/Img/Note04-1-11.bmp)   
>  ![Note04-1-12](/Img/Note04-1-12.bmp)   
>
> 训练完成后，大部分训练样本均不保留，最终模型仅与支持向量有关，占用内存少，预测快；  
> 适合数据维度高，数据量小的情况，因为调参耗时，时间复杂度大。  

可以参考保姆级基础教程了解相关知识：[https://zhuanlan.zhihu.com/p/77750026]（https://zhuanlan.zhihu.com/p/77750026） 

